{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d547f731",
   "metadata": {},
   "source": [
    "# Part One\n",
    "Import required tools for collecting and cleaning the data: <br>\n",
    "* Some tools are more commonly used\n",
    "* Some tools are specific to the Alpha Vantage API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "40129ff4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()\n",
    "ALPHA_VANTAGE_API_KEY = os.getenv('secret')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8f0408c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import requests\n",
    "import collections\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from ast import literal_eval\n",
    "import numpy as np\n",
    "import datetime\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression\n",
    "import scipy.stats as sp\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bc554d6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from alpha_vantage.foreignexchange import ForeignExchange\n",
    "from alpha_vantage.timeseries import TimeSeries\n",
    "\n",
    "import asyncio\n",
    "from alpha_vantage.async_support.timeseries import TimeSeries"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dcb289ed",
   "metadata": {},
   "source": [
    "# Part Two\n",
    "Obtain forex data from the Alpha Vantage API: <br>\n",
    "* I am obtaining pricing data for the past 100 days for pairings of the top ten most traded currencies <br>\n",
    "* For each pairing I am taking only the data required into a pandas dataframe, adding a column for \"to\" and \"from\" symbol to keep track of each currency, and then concatenating the dataframes into a large dataframe for easier use"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2fa72d1b",
   "metadata": {},
   "source": [
    "* Assign API call to a variable \"app\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4992bbb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "app = ForeignExchange(key=ALPHA_VANTAGE_API_KEY, output_format='pandas')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6a730c7",
   "metadata": {},
   "source": [
    "* Create empty dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1a51fde4",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_pairs = pd.DataFrame()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e11fabf",
   "metadata": {},
   "source": [
    "Here we initialize two lists:\n",
    "* CURRENCY_1: the currency we are converting FROM\n",
    "* CURRENCY_2: the currency we are converting TO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "71a706db",
   "metadata": {},
   "outputs": [],
   "source": [
    "CURRENCY_1 = ('USD',)\n",
    "CURRENCY_2 = ('USD', 'EUR', 'JPY', 'GBP', 'AUD',)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c63ebecc",
   "metadata": {},
   "source": [
    "Create the for loop:\n",
    "* Double for loop to iterate through CURRENCY_1 and CURRENCY_2\n",
    "* If statement to be sure that currency is not converted to itself\n",
    "* Restrict data to usable part returned by API\n",
    "* Create columns for \"to symbol\" and \"from symbol\"\n",
    "* Rename columns for ease of use\n",
    "* Convert to datetime, sort index\n",
    "* Add features\n",
    "* Reorder columns\n",
    "* Concatenate to main dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2241947b",
   "metadata": {},
   "outputs": [],
   "source": [
    "for c1 in CURRENCY_1:\n",
    "  for c2 in CURRENCY_2:\n",
    "    if c1 != c2:\n",
    "      currconv = app.get_currency_exchange_daily(c1, c2)\n",
    "      currconv1 = currconv[0]\n",
    "      currconv1['to symbol'] = c2\n",
    "      currconv1['from symbol'] = c1\n",
    "\n",
    "      currconv1.rename(columns={'1. open': 'open'}, inplace=True)\n",
    "      currconv1.rename(columns={'2. high': 'high'}, inplace=True)\n",
    "      currconv1.rename(columns={'3. low': 'low'}, inplace=True)\n",
    "      currconv1.rename(columns={'4. close': 'close'}, inplace=True)\n",
    "\n",
    "      pd.to_datetime(currconv1.index)\n",
    "      currconv1 = currconv1.sort_index()\n",
    "\n",
    "      currconv1['time'] = np.arange(len(currconv1.index))\n",
    "\n",
    "      currconv1['lag_1'] = currconv1['close'].shift(1)\n",
    "      currconv1['lag_2'] = currconv1['close'].shift(2)\n",
    "      currconv1['lag_3'] = currconv1['close'].shift(3)\n",
    "      currconv1['lag_4'] = currconv1['close'].shift(4)\n",
    "      currconv1['lag_5'] = currconv1['close'].shift(5)\n",
    "      currconv1['lag_6'] = currconv1['close'].shift(6)\n",
    "      currconv1['lag_7'] = currconv1['close'].shift(7)\n",
    "\n",
    "      currconv1['rolling_mean'] = currconv1['close'].rolling(window=7).mean()\n",
    "      currconv1['expanding_mean'] = currconv1['close'].expanding(2).mean()\n",
    "\n",
    "      currconv1 = currconv1[['from symbol', 'to symbol', 'open', 'high', 'low', 'close', 'lag_1', 'lag_2', 'lag_3', 'lag_4', 'lag_5', 'lag_6', 'lag_7', 'rolling_mean', 'expanding_mean', 'time']]\n",
    "\n",
    "      all_pairs = pd.concat([all_pairs, currconv1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "688f7cff",
   "metadata": {},
   "source": [
    "* Repeat for all other currencies:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ff802d82",
   "metadata": {},
   "outputs": [],
   "source": [
    "CURRENCY_1 = ('USD',)\n",
    "CURRENCY_2 = ('CHF', 'CAD', 'HKD', 'SEK', 'NZD',)\n",
    "\n",
    "\n",
    "for c1 in CURRENCY_1:\n",
    "  for c2 in CURRENCY_2:\n",
    "    if c1 != c2:\n",
    "      currconv = app.get_currency_exchange_daily(c1, c2)\n",
    "      currconv1 = currconv[0]\n",
    "      currconv1['to symbol'] = c2\n",
    "      currconv1['from symbol'] = c1\n",
    "\n",
    "      currconv1.rename(columns={'1. open': 'open'}, inplace=True)\n",
    "      currconv1.rename(columns={'2. high': 'high'}, inplace=True)\n",
    "      currconv1.rename(columns={'3. low': 'low'}, inplace=True)\n",
    "      currconv1.rename(columns={'4. close': 'close'}, inplace=True)\n",
    "\n",
    "      pd.to_datetime(currconv1.index)\n",
    "      currconv1 = currconv1.sort_index()\n",
    "\n",
    "      currconv1['time'] = np.arange(len(currconv1.index))\n",
    "\n",
    "      currconv1['lag_1'] = currconv1['close'].shift(1)\n",
    "      currconv1['lag_2'] = currconv1['close'].shift(2)\n",
    "      currconv1['lag_3'] = currconv1['close'].shift(3)\n",
    "      currconv1['lag_4'] = currconv1['close'].shift(4)\n",
    "      currconv1['lag_5'] = currconv1['close'].shift(5)\n",
    "      currconv1['lag_6'] = currconv1['close'].shift(6)\n",
    "      currconv1['lag_7'] = currconv1['close'].shift(7)\n",
    "\n",
    "      currconv1['rolling_mean'] = currconv1['close'].rolling(window=7).mean()\n",
    "      currconv1['expanding_mean'] = currconv1['close'].expanding(2).mean()\n",
    "\n",
    "      currconv1 = currconv1[['from symbol', 'to symbol', 'open', 'high', 'low', 'close', 'lag_1', 'lag_2', 'lag_3', 'lag_4', 'lag_5', 'lag_6', 'lag_7', 'rolling_mean', 'expanding_mean', 'time']]\n",
    "\n",
    "      all_pairs = pd.concat([all_pairs, currconv1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c2de9ede",
   "metadata": {},
   "outputs": [],
   "source": [
    "CURRENCY_1 = ('EUR',)\n",
    "CURRENCY_2 = ('USD', 'EUR', 'JPY', 'GBP', 'AUD',)\n",
    "\n",
    "\n",
    "for c1 in CURRENCY_1:\n",
    "  for c2 in CURRENCY_2:\n",
    "    if c1 != c2:\n",
    "      currconv = app.get_currency_exchange_daily(c1, c2)\n",
    "      currconv1 = currconv[0]\n",
    "      currconv1['to symbol'] = c2\n",
    "      currconv1['from symbol'] = c1\n",
    "\n",
    "      currconv1.rename(columns={'1. open': 'open'}, inplace=True)\n",
    "      currconv1.rename(columns={'2. high': 'high'}, inplace=True)\n",
    "      currconv1.rename(columns={'3. low': 'low'}, inplace=True)\n",
    "      currconv1.rename(columns={'4. close': 'close'}, inplace=True)\n",
    "\n",
    "      pd.to_datetime(currconv1.index)\n",
    "      currconv1 = currconv1.sort_index()\n",
    "\n",
    "      currconv1['time'] = np.arange(len(currconv1.index))\n",
    "\n",
    "      currconv1['lag_1'] = currconv1['close'].shift(1)\n",
    "      currconv1['lag_2'] = currconv1['close'].shift(2)\n",
    "      currconv1['lag_3'] = currconv1['close'].shift(3)\n",
    "      currconv1['lag_4'] = currconv1['close'].shift(4)\n",
    "      currconv1['lag_5'] = currconv1['close'].shift(5)\n",
    "      currconv1['lag_6'] = currconv1['close'].shift(6)\n",
    "      currconv1['lag_7'] = currconv1['close'].shift(7)\n",
    "\n",
    "      currconv1['rolling_mean'] = currconv1['close'].rolling(window=7).mean()\n",
    "      currconv1['expanding_mean'] = currconv1['close'].expanding(2).mean()\n",
    "\n",
    "      currconv1 = currconv1[['from symbol', 'to symbol', 'open', 'high', 'low', 'close', 'lag_1', 'lag_2', 'lag_3', 'lag_4', 'lag_5', 'lag_6', 'lag_7', 'rolling_mean', 'expanding_mean', 'time']]\n",
    "\n",
    "      all_pairs = pd.concat([all_pairs, currconv1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8794d7b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "CURRENCY_1 = ('EUR',)\n",
    "CURRENCY_2 = ('CHF', 'CAD', 'HKD', 'SEK', 'NZD',)\n",
    "\n",
    "\n",
    "for c1 in CURRENCY_1:\n",
    "  for c2 in CURRENCY_2:\n",
    "    if c1 != c2:\n",
    "      currconv = app.get_currency_exchange_daily(c1, c2)\n",
    "      currconv1 = currconv[0]\n",
    "      currconv1['to symbol'] = c2\n",
    "      currconv1['from symbol'] = c1\n",
    "\n",
    "      currconv1.rename(columns={'1. open': 'open'}, inplace=True)\n",
    "      currconv1.rename(columns={'2. high': 'high'}, inplace=True)\n",
    "      currconv1.rename(columns={'3. low': 'low'}, inplace=True)\n",
    "      currconv1.rename(columns={'4. close': 'close'}, inplace=True)\n",
    "\n",
    "      pd.to_datetime(currconv1.index)\n",
    "      currconv1 = currconv1.sort_index()\n",
    "\n",
    "      currconv1['time'] = np.arange(len(currconv1.index))\n",
    "\n",
    "      currconv1['lag_1'] = currconv1['close'].shift(1)\n",
    "      currconv1['lag_2'] = currconv1['close'].shift(2)\n",
    "      currconv1['lag_3'] = currconv1['close'].shift(3)\n",
    "      currconv1['lag_4'] = currconv1['close'].shift(4)\n",
    "      currconv1['lag_5'] = currconv1['close'].shift(5)\n",
    "      currconv1['lag_6'] = currconv1['close'].shift(6)\n",
    "      currconv1['lag_7'] = currconv1['close'].shift(7)\n",
    "\n",
    "      currconv1['rolling_mean'] = currconv1['close'].rolling(window=7).mean()\n",
    "      currconv1['expanding_mean'] = currconv1['close'].expanding(2).mean()\n",
    "\n",
    "      currconv1 = currconv1[['from symbol', 'to symbol', 'open', 'high', 'low', 'close', 'lag_1', 'lag_2', 'lag_3', 'lag_4', 'lag_5', 'lag_6', 'lag_7', 'rolling_mean', 'expanding_mean', 'time']]\n",
    "\n",
    "      all_pairs = pd.concat([all_pairs, currconv1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "aaf0ebd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "CURRENCY_1 = ('JPY',)\n",
    "CURRENCY_2 = ('USD', 'EUR', 'JPY', 'GBP', 'AUD',)\n",
    "\n",
    "\n",
    "for c1 in CURRENCY_1:\n",
    "  for c2 in CURRENCY_2:\n",
    "    if c1 != c2:\n",
    "      currconv = app.get_currency_exchange_daily(c1, c2)\n",
    "      currconv1 = currconv[0]\n",
    "      currconv1['to symbol'] = c2\n",
    "      currconv1['from symbol'] = c1\n",
    "\n",
    "      currconv1.rename(columns={'1. open': 'open'}, inplace=True)\n",
    "      currconv1.rename(columns={'2. high': 'high'}, inplace=True)\n",
    "      currconv1.rename(columns={'3. low': 'low'}, inplace=True)\n",
    "      currconv1.rename(columns={'4. close': 'close'}, inplace=True)\n",
    "\n",
    "      pd.to_datetime(currconv1.index)\n",
    "      currconv1 = currconv1.sort_index()\n",
    "\n",
    "      currconv1['time'] = np.arange(len(currconv1.index))\n",
    "\n",
    "      currconv1['lag_1'] = currconv1['close'].shift(1)\n",
    "      currconv1['lag_2'] = currconv1['close'].shift(2)\n",
    "      currconv1['lag_3'] = currconv1['close'].shift(3)\n",
    "      currconv1['lag_4'] = currconv1['close'].shift(4)\n",
    "      currconv1['lag_5'] = currconv1['close'].shift(5)\n",
    "      currconv1['lag_6'] = currconv1['close'].shift(6)\n",
    "      currconv1['lag_7'] = currconv1['close'].shift(7)\n",
    "\n",
    "      currconv1['rolling_mean'] = currconv1['close'].rolling(window=7).mean()\n",
    "      currconv1['expanding_mean'] = currconv1['close'].expanding(2).mean()\n",
    "\n",
    "      currconv1 = currconv1[['from symbol', 'to symbol', 'open', 'high', 'low', 'close', 'lag_1', 'lag_2', 'lag_3', 'lag_4', 'lag_5', 'lag_6', 'lag_7', 'rolling_mean', 'expanding_mean', 'time']]\n",
    "\n",
    "      all_pairs = pd.concat([all_pairs, currconv1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6ed5dfd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "CURRENCY_1 = ('JPY',)\n",
    "CURRENCY_2 = ('CHF', 'CAD', 'HKD', 'SEK', 'NZD',)\n",
    "\n",
    "\n",
    "for c1 in CURRENCY_1:\n",
    "  for c2 in CURRENCY_2:\n",
    "    if c1 != c2:\n",
    "      currconv = app.get_currency_exchange_daily(c1, c2)\n",
    "      currconv1 = currconv[0]\n",
    "      currconv1['to symbol'] = c2\n",
    "      currconv1['from symbol'] = c1\n",
    "\n",
    "      currconv1.rename(columns={'1. open': 'open'}, inplace=True)\n",
    "      currconv1.rename(columns={'2. high': 'high'}, inplace=True)\n",
    "      currconv1.rename(columns={'3. low': 'low'}, inplace=True)\n",
    "      currconv1.rename(columns={'4. close': 'close'}, inplace=True)\n",
    "\n",
    "      pd.to_datetime(currconv1.index)\n",
    "      currconv1 = currconv1.sort_index()\n",
    "\n",
    "      currconv1['time'] = np.arange(len(currconv1.index))\n",
    "\n",
    "      currconv1['lag_1'] = currconv1['close'].shift(1)\n",
    "      currconv1['lag_2'] = currconv1['close'].shift(2)\n",
    "      currconv1['lag_3'] = currconv1['close'].shift(3)\n",
    "      currconv1['lag_4'] = currconv1['close'].shift(4)\n",
    "      currconv1['lag_5'] = currconv1['close'].shift(5)\n",
    "      currconv1['lag_6'] = currconv1['close'].shift(6)\n",
    "      currconv1['lag_7'] = currconv1['close'].shift(7)\n",
    "\n",
    "      currconv1['rolling_mean'] = currconv1['close'].rolling(window=7).mean()\n",
    "      currconv1['expanding_mean'] = currconv1['close'].expanding(2).mean()\n",
    "\n",
    "      currconv1 = currconv1[['from symbol', 'to symbol', 'open', 'high', 'low', 'close', 'lag_1', 'lag_2', 'lag_3', 'lag_4', 'lag_5', 'lag_6', 'lag_7', 'rolling_mean', 'expanding_mean', 'time']]\n",
    "\n",
    "      all_pairs = pd.concat([all_pairs, currconv1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f2f0e746",
   "metadata": {},
   "outputs": [],
   "source": [
    "CURRENCY_1 = ('GBP',)\n",
    "CURRENCY_2 = ('USD', 'EUR', 'JPY', 'GBP', 'AUD',)\n",
    "\n",
    "\n",
    "for c1 in CURRENCY_1:\n",
    "  for c2 in CURRENCY_2:\n",
    "    if c1 != c2:\n",
    "      currconv = app.get_currency_exchange_daily(c1, c2)\n",
    "      currconv1 = currconv[0]\n",
    "      currconv1['to symbol'] = c2\n",
    "      currconv1['from symbol'] = c1\n",
    "\n",
    "      currconv1.rename(columns={'1. open': 'open'}, inplace=True)\n",
    "      currconv1.rename(columns={'2. high': 'high'}, inplace=True)\n",
    "      currconv1.rename(columns={'3. low': 'low'}, inplace=True)\n",
    "      currconv1.rename(columns={'4. close': 'close'}, inplace=True)\n",
    "\n",
    "      pd.to_datetime(currconv1.index)\n",
    "      currconv1 = currconv1.sort_index()\n",
    "\n",
    "      currconv1['time'] = np.arange(len(currconv1.index))\n",
    "\n",
    "      currconv1['lag_1'] = currconv1['close'].shift(1)\n",
    "      currconv1['lag_2'] = currconv1['close'].shift(2)\n",
    "      currconv1['lag_3'] = currconv1['close'].shift(3)\n",
    "      currconv1['lag_4'] = currconv1['close'].shift(4)\n",
    "      currconv1['lag_5'] = currconv1['close'].shift(5)\n",
    "      currconv1['lag_6'] = currconv1['close'].shift(6)\n",
    "      currconv1['lag_7'] = currconv1['close'].shift(7)\n",
    "\n",
    "      currconv1['rolling_mean'] = currconv1['close'].rolling(window=7).mean()\n",
    "      currconv1['expanding_mean'] = currconv1['close'].expanding(2).mean()\n",
    "\n",
    "      currconv1 = currconv1[['from symbol', 'to symbol', 'open', 'high', 'low', 'close', 'lag_1', 'lag_2', 'lag_3', 'lag_4', 'lag_5', 'lag_6', 'lag_7', 'rolling_mean', 'expanding_mean', 'time']]\n",
    "\n",
    "      all_pairs = pd.concat([all_pairs, currconv1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "11409973",
   "metadata": {},
   "outputs": [],
   "source": [
    "CURRENCY_1 = ('GBP',)\n",
    "CURRENCY_2 = ('CHF', 'CAD', 'HKD', 'SEK', 'NZD',)\n",
    "\n",
    "\n",
    "for c1 in CURRENCY_1:\n",
    "  for c2 in CURRENCY_2:\n",
    "    if c1 != c2:\n",
    "      currconv = app.get_currency_exchange_daily(c1, c2)\n",
    "      currconv1 = currconv[0]\n",
    "      currconv1['to symbol'] = c2\n",
    "      currconv1['from symbol'] = c1\n",
    "\n",
    "      currconv1.rename(columns={'1. open': 'open'}, inplace=True)\n",
    "      currconv1.rename(columns={'2. high': 'high'}, inplace=True)\n",
    "      currconv1.rename(columns={'3. low': 'low'}, inplace=True)\n",
    "      currconv1.rename(columns={'4. close': 'close'}, inplace=True)\n",
    "\n",
    "      pd.to_datetime(currconv1.index)\n",
    "      currconv1 = currconv1.sort_index()\n",
    "\n",
    "      currconv1['time'] = np.arange(len(currconv1.index))\n",
    "\n",
    "      currconv1['lag_1'] = currconv1['close'].shift(1)\n",
    "      currconv1['lag_2'] = currconv1['close'].shift(2)\n",
    "      currconv1['lag_3'] = currconv1['close'].shift(3)\n",
    "      currconv1['lag_4'] = currconv1['close'].shift(4)\n",
    "      currconv1['lag_5'] = currconv1['close'].shift(5)\n",
    "      currconv1['lag_6'] = currconv1['close'].shift(6)\n",
    "      currconv1['lag_7'] = currconv1['close'].shift(7)\n",
    "\n",
    "      currconv1['rolling_mean'] = currconv1['close'].rolling(window=7).mean()\n",
    "      currconv1['expanding_mean'] = currconv1['close'].expanding(2).mean()\n",
    "\n",
    "      currconv1 = currconv1[['from symbol', 'to symbol', 'open', 'high', 'low', 'close', 'lag_1', 'lag_2', 'lag_3', 'lag_4', 'lag_5', 'lag_6', 'lag_7', 'rolling_mean', 'expanding_mean', 'time']]\n",
    "\n",
    "      all_pairs = pd.concat([all_pairs, currconv1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "7d2c7ba9",
   "metadata": {},
   "outputs": [],
   "source": [
    "CURRENCY_1 = ('AUD',)\n",
    "CURRENCY_2 = ('USD', 'EUR', 'JPY', 'GBP', 'AUD',)\n",
    "\n",
    "\n",
    "for c1 in CURRENCY_1:\n",
    "  for c2 in CURRENCY_2:\n",
    "    if c1 != c2:\n",
    "      currconv = app.get_currency_exchange_daily(c1, c2)\n",
    "      currconv1 = currconv[0]\n",
    "      currconv1['to symbol'] = c2\n",
    "      currconv1['from symbol'] = c1\n",
    "\n",
    "      currconv1.rename(columns={'1. open': 'open'}, inplace=True)\n",
    "      currconv1.rename(columns={'2. high': 'high'}, inplace=True)\n",
    "      currconv1.rename(columns={'3. low': 'low'}, inplace=True)\n",
    "      currconv1.rename(columns={'4. close': 'close'}, inplace=True)\n",
    "\n",
    "      pd.to_datetime(currconv1.index)\n",
    "      currconv1 = currconv1.sort_index()\n",
    "\n",
    "      currconv1['time'] = np.arange(len(currconv1.index))\n",
    "\n",
    "      currconv1['lag_1'] = currconv1['close'].shift(1)\n",
    "      currconv1['lag_2'] = currconv1['close'].shift(2)\n",
    "      currconv1['lag_3'] = currconv1['close'].shift(3)\n",
    "      currconv1['lag_4'] = currconv1['close'].shift(4)\n",
    "      currconv1['lag_5'] = currconv1['close'].shift(5)\n",
    "      currconv1['lag_6'] = currconv1['close'].shift(6)\n",
    "      currconv1['lag_7'] = currconv1['close'].shift(7)\n",
    "\n",
    "      currconv1['rolling_mean'] = currconv1['close'].rolling(window=7).mean()\n",
    "      currconv1['expanding_mean'] = currconv1['close'].expanding(2).mean()\n",
    "\n",
    "      currconv1 = currconv1[['from symbol', 'to symbol', 'open', 'high', 'low', 'close', 'lag_1', 'lag_2', 'lag_3', 'lag_4', 'lag_5', 'lag_6', 'lag_7', 'rolling_mean', 'expanding_mean', 'time']]\n",
    "\n",
    "      all_pairs = pd.concat([all_pairs, currconv1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "70fe01a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "CURRENCY_1 = ('AUD',)\n",
    "CURRENCY_2 = ('CHF', 'CAD', 'HKD', 'SEK', 'NZD',)\n",
    "\n",
    "\n",
    "for c1 in CURRENCY_1:\n",
    "  for c2 in CURRENCY_2:\n",
    "    if c1 != c2:\n",
    "      currconv = app.get_currency_exchange_daily(c1, c2)\n",
    "      currconv1 = currconv[0]\n",
    "      currconv1['to symbol'] = c2\n",
    "      currconv1['from symbol'] = c1\n",
    "\n",
    "      currconv1.rename(columns={'1. open': 'open'}, inplace=True)\n",
    "      currconv1.rename(columns={'2. high': 'high'}, inplace=True)\n",
    "      currconv1.rename(columns={'3. low': 'low'}, inplace=True)\n",
    "      currconv1.rename(columns={'4. close': 'close'}, inplace=True)\n",
    "\n",
    "      pd.to_datetime(currconv1.index)\n",
    "      currconv1 = currconv1.sort_index()\n",
    "\n",
    "      currconv1['time'] = np.arange(len(currconv1.index))\n",
    "\n",
    "      currconv1['lag_1'] = currconv1['close'].shift(1)\n",
    "      currconv1['lag_2'] = currconv1['close'].shift(2)\n",
    "      currconv1['lag_3'] = currconv1['close'].shift(3)\n",
    "      currconv1['lag_4'] = currconv1['close'].shift(4)\n",
    "      currconv1['lag_5'] = currconv1['close'].shift(5)\n",
    "      currconv1['lag_6'] = currconv1['close'].shift(6)\n",
    "      currconv1['lag_7'] = currconv1['close'].shift(7)\n",
    "\n",
    "      currconv1['rolling_mean'] = currconv1['close'].rolling(window=7).mean()\n",
    "      currconv1['expanding_mean'] = currconv1['close'].expanding(2).mean()\n",
    "\n",
    "      currconv1 = currconv1[['from symbol', 'to symbol', 'open', 'high', 'low', 'close', 'lag_1', 'lag_2', 'lag_3', 'lag_4', 'lag_5', 'lag_6', 'lag_7', 'rolling_mean', 'expanding_mean', 'time']]\n",
    "\n",
    "      all_pairs = pd.concat([all_pairs, currconv1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "78e32067",
   "metadata": {},
   "outputs": [],
   "source": [
    "CURRENCY_1 = ('CHF',)\n",
    "CURRENCY_2 = ('USD', 'EUR', 'JPY', 'GBP', 'AUD',)\n",
    "\n",
    "\n",
    "for c1 in CURRENCY_1:\n",
    "  for c2 in CURRENCY_2:\n",
    "    if c1 != c2:\n",
    "      currconv = app.get_currency_exchange_daily(c1, c2)\n",
    "      currconv1 = currconv[0]\n",
    "      currconv1['to symbol'] = c2\n",
    "      currconv1['from symbol'] = c1\n",
    "\n",
    "      currconv1.rename(columns={'1. open': 'open'}, inplace=True)\n",
    "      currconv1.rename(columns={'2. high': 'high'}, inplace=True)\n",
    "      currconv1.rename(columns={'3. low': 'low'}, inplace=True)\n",
    "      currconv1.rename(columns={'4. close': 'close'}, inplace=True)\n",
    "\n",
    "      pd.to_datetime(currconv1.index)\n",
    "      currconv1 = currconv1.sort_index()\n",
    "\n",
    "      currconv1['time'] = np.arange(len(currconv1.index))\n",
    "\n",
    "      currconv1['lag_1'] = currconv1['close'].shift(1)\n",
    "      currconv1['lag_2'] = currconv1['close'].shift(2)\n",
    "      currconv1['lag_3'] = currconv1['close'].shift(3)\n",
    "      currconv1['lag_4'] = currconv1['close'].shift(4)\n",
    "      currconv1['lag_5'] = currconv1['close'].shift(5)\n",
    "      currconv1['lag_6'] = currconv1['close'].shift(6)\n",
    "      currconv1['lag_7'] = currconv1['close'].shift(7)\n",
    "\n",
    "      currconv1['rolling_mean'] = currconv1['close'].rolling(window=7).mean()\n",
    "      currconv1['expanding_mean'] = currconv1['close'].expanding(2).mean()\n",
    "\n",
    "      currconv1 = currconv1[['from symbol', 'to symbol', 'open', 'high', 'low', 'close', 'lag_1', 'lag_2', 'lag_3', 'lag_4', 'lag_5', 'lag_6', 'lag_7', 'rolling_mean', 'expanding_mean', 'time']]\n",
    "\n",
    "      all_pairs = pd.concat([all_pairs, currconv1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "30121f11",
   "metadata": {},
   "outputs": [],
   "source": [
    "CURRENCY_1 = ('CHF',)\n",
    "CURRENCY_2 = ('CHF', 'CAD', 'HKD', 'SEK', 'NZD',)\n",
    "\n",
    "\n",
    "for c1 in CURRENCY_1:\n",
    "  for c2 in CURRENCY_2:\n",
    "    if c1 != c2:\n",
    "      currconv = app.get_currency_exchange_daily(c1, c2)\n",
    "      currconv1 = currconv[0]\n",
    "      currconv1['to symbol'] = c2\n",
    "      currconv1['from symbol'] = c1\n",
    "\n",
    "      currconv1.rename(columns={'1. open': 'open'}, inplace=True)\n",
    "      currconv1.rename(columns={'2. high': 'high'}, inplace=True)\n",
    "      currconv1.rename(columns={'3. low': 'low'}, inplace=True)\n",
    "      currconv1.rename(columns={'4. close': 'close'}, inplace=True)\n",
    "\n",
    "      pd.to_datetime(currconv1.index)\n",
    "      currconv1 = currconv1.sort_index()\n",
    "\n",
    "      currconv1['time'] = np.arange(len(currconv1.index))\n",
    "\n",
    "      currconv1['lag_1'] = currconv1['close'].shift(1)\n",
    "      currconv1['lag_2'] = currconv1['close'].shift(2)\n",
    "      currconv1['lag_3'] = currconv1['close'].shift(3)\n",
    "      currconv1['lag_4'] = currconv1['close'].shift(4)\n",
    "      currconv1['lag_5'] = currconv1['close'].shift(5)\n",
    "      currconv1['lag_6'] = currconv1['close'].shift(6)\n",
    "      currconv1['lag_7'] = currconv1['close'].shift(7)\n",
    "\n",
    "      currconv1['rolling_mean'] = currconv1['close'].rolling(window=7).mean()\n",
    "      currconv1['expanding_mean'] = currconv1['close'].expanding(2).mean()\n",
    "\n",
    "      currconv1 = currconv1[['from symbol', 'to symbol', 'open', 'high', 'low', 'close', 'lag_1', 'lag_2', 'lag_3', 'lag_4', 'lag_5', 'lag_6', 'lag_7', 'rolling_mean', 'expanding_mean', 'time']]\n",
    "\n",
    "      all_pairs = pd.concat([all_pairs, currconv1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "1c78c1a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "CURRENCY_1 = ('CAD',)\n",
    "CURRENCY_2 = ('USD', 'EUR', 'JPY', 'GBP', 'AUD',)\n",
    "\n",
    "\n",
    "for c1 in CURRENCY_1:\n",
    "  for c2 in CURRENCY_2:\n",
    "    if c1 != c2:\n",
    "      currconv = app.get_currency_exchange_daily(c1, c2)\n",
    "      currconv1 = currconv[0]\n",
    "      currconv1['to symbol'] = c2\n",
    "      currconv1['from symbol'] = c1\n",
    "\n",
    "      currconv1.rename(columns={'1. open': 'open'}, inplace=True)\n",
    "      currconv1.rename(columns={'2. high': 'high'}, inplace=True)\n",
    "      currconv1.rename(columns={'3. low': 'low'}, inplace=True)\n",
    "      currconv1.rename(columns={'4. close': 'close'}, inplace=True)\n",
    "\n",
    "      pd.to_datetime(currconv1.index)\n",
    "      currconv1 = currconv1.sort_index()\n",
    "\n",
    "      currconv1['time'] = np.arange(len(currconv1.index))\n",
    "\n",
    "      currconv1['lag_1'] = currconv1['close'].shift(1)\n",
    "      currconv1['lag_2'] = currconv1['close'].shift(2)\n",
    "      currconv1['lag_3'] = currconv1['close'].shift(3)\n",
    "      currconv1['lag_4'] = currconv1['close'].shift(4)\n",
    "      currconv1['lag_5'] = currconv1['close'].shift(5)\n",
    "      currconv1['lag_6'] = currconv1['close'].shift(6)\n",
    "      currconv1['lag_7'] = currconv1['close'].shift(7)\n",
    "\n",
    "      currconv1['rolling_mean'] = currconv1['close'].rolling(window=7).mean()\n",
    "      currconv1['expanding_mean'] = currconv1['close'].expanding(2).mean()\n",
    "\n",
    "      currconv1 = currconv1[['from symbol', 'to symbol', 'open', 'high', 'low', 'close', 'lag_1', 'lag_2', 'lag_3', 'lag_4', 'lag_5', 'lag_6', 'lag_7', 'rolling_mean', 'expanding_mean', 'time']]\n",
    "\n",
    "      all_pairs = pd.concat([all_pairs, currconv1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "730ddf53",
   "metadata": {},
   "outputs": [],
   "source": [
    "CURRENCY_1 = ('CAD',)\n",
    "CURRENCY_2 = ('CHF', 'CAD', 'HKD', 'SEK', 'NZD',)\n",
    "\n",
    "\n",
    "for c1 in CURRENCY_1:\n",
    "  for c2 in CURRENCY_2:\n",
    "    if c1 != c2:\n",
    "      currconv = app.get_currency_exchange_daily(c1, c2)\n",
    "      currconv1 = currconv[0]\n",
    "      currconv1['to symbol'] = c2\n",
    "      currconv1['from symbol'] = c1\n",
    "\n",
    "      currconv1.rename(columns={'1. open': 'open'}, inplace=True)\n",
    "      currconv1.rename(columns={'2. high': 'high'}, inplace=True)\n",
    "      currconv1.rename(columns={'3. low': 'low'}, inplace=True)\n",
    "      currconv1.rename(columns={'4. close': 'close'}, inplace=True)\n",
    "\n",
    "      pd.to_datetime(currconv1.index)\n",
    "      currconv1 = currconv1.sort_index()\n",
    "\n",
    "      currconv1['time'] = np.arange(len(currconv1.index))\n",
    "\n",
    "      currconv1['lag_1'] = currconv1['close'].shift(1)\n",
    "      currconv1['lag_2'] = currconv1['close'].shift(2)\n",
    "      currconv1['lag_3'] = currconv1['close'].shift(3)\n",
    "      currconv1['lag_4'] = currconv1['close'].shift(4)\n",
    "      currconv1['lag_5'] = currconv1['close'].shift(5)\n",
    "      currconv1['lag_6'] = currconv1['close'].shift(6)\n",
    "      currconv1['lag_7'] = currconv1['close'].shift(7)\n",
    "\n",
    "      currconv1['rolling_mean'] = currconv1['close'].rolling(window=7).mean()\n",
    "      currconv1['expanding_mean'] = currconv1['close'].expanding(2).mean()\n",
    "\n",
    "      currconv1 = currconv1[['from symbol', 'to symbol', 'open', 'high', 'low', 'close', 'lag_1', 'lag_2', 'lag_3', 'lag_4', 'lag_5', 'lag_6', 'lag_7', 'rolling_mean', 'expanding_mean', 'time']]\n",
    "\n",
    "      all_pairs = pd.concat([all_pairs, currconv1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "d121639a",
   "metadata": {},
   "outputs": [],
   "source": [
    "CURRENCY_1 = ('HKD',)\n",
    "CURRENCY_2 = ('USD', 'EUR', 'JPY', 'GBP', 'AUD',)\n",
    "\n",
    "\n",
    "for c1 in CURRENCY_1:\n",
    "  for c2 in CURRENCY_2:\n",
    "    if c1 != c2:\n",
    "      currconv = app.get_currency_exchange_daily(c1, c2)\n",
    "      currconv1 = currconv[0]\n",
    "      currconv1['to symbol'] = c2\n",
    "      currconv1['from symbol'] = c1\n",
    "\n",
    "      currconv1.rename(columns={'1. open': 'open'}, inplace=True)\n",
    "      currconv1.rename(columns={'2. high': 'high'}, inplace=True)\n",
    "      currconv1.rename(columns={'3. low': 'low'}, inplace=True)\n",
    "      currconv1.rename(columns={'4. close': 'close'}, inplace=True)\n",
    "\n",
    "      pd.to_datetime(currconv1.index)\n",
    "      currconv1 = currconv1.sort_index()\n",
    "\n",
    "      currconv1['time'] = np.arange(len(currconv1.index))\n",
    "\n",
    "      currconv1['lag_1'] = currconv1['close'].shift(1)\n",
    "      currconv1['lag_2'] = currconv1['close'].shift(2)\n",
    "      currconv1['lag_3'] = currconv1['close'].shift(3)\n",
    "      currconv1['lag_4'] = currconv1['close'].shift(4)\n",
    "      currconv1['lag_5'] = currconv1['close'].shift(5)\n",
    "      currconv1['lag_6'] = currconv1['close'].shift(6)\n",
    "      currconv1['lag_7'] = currconv1['close'].shift(7)\n",
    "\n",
    "      currconv1['rolling_mean'] = currconv1['close'].rolling(window=7).mean()\n",
    "      currconv1['expanding_mean'] = currconv1['close'].expanding(2).mean()\n",
    "\n",
    "      currconv1 = currconv1[['from symbol', 'to symbol', 'open', 'high', 'low', 'close', 'lag_1', 'lag_2', 'lag_3', 'lag_4', 'lag_5', 'lag_6', 'lag_7', 'rolling_mean', 'expanding_mean', 'time']]\n",
    "\n",
    "      all_pairs = pd.concat([all_pairs, currconv1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "d9ff79f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "CURRENCY_1 = ('HKD',)\n",
    "CURRENCY_2 = ('CHF', 'CAD', 'HKD', 'SEK', 'NZD',)\n",
    "\n",
    "\n",
    "for c1 in CURRENCY_1:\n",
    "  for c2 in CURRENCY_2:\n",
    "    if c1 != c2:\n",
    "      currconv = app.get_currency_exchange_daily(c1, c2)\n",
    "      currconv1 = currconv[0]\n",
    "      currconv1['to symbol'] = c2\n",
    "      currconv1['from symbol'] = c1\n",
    "\n",
    "      currconv1.rename(columns={'1. open': 'open'}, inplace=True)\n",
    "      currconv1.rename(columns={'2. high': 'high'}, inplace=True)\n",
    "      currconv1.rename(columns={'3. low': 'low'}, inplace=True)\n",
    "      currconv1.rename(columns={'4. close': 'close'}, inplace=True)\n",
    "\n",
    "      pd.to_datetime(currconv1.index)\n",
    "      currconv1 = currconv1.sort_index()\n",
    "\n",
    "      currconv1['time'] = np.arange(len(currconv1.index))\n",
    "\n",
    "      currconv1['lag_1'] = currconv1['close'].shift(1)\n",
    "      currconv1['lag_2'] = currconv1['close'].shift(2)\n",
    "      currconv1['lag_3'] = currconv1['close'].shift(3)\n",
    "      currconv1['lag_4'] = currconv1['close'].shift(4)\n",
    "      currconv1['lag_5'] = currconv1['close'].shift(5)\n",
    "      currconv1['lag_6'] = currconv1['close'].shift(6)\n",
    "      currconv1['lag_7'] = currconv1['close'].shift(7)\n",
    "\n",
    "      currconv1['rolling_mean'] = currconv1['close'].rolling(window=7).mean()\n",
    "      currconv1['expanding_mean'] = currconv1['close'].expanding(2).mean()\n",
    "\n",
    "      currconv1 = currconv1[['from symbol', 'to symbol', 'open', 'high', 'low', 'close', 'lag_1', 'lag_2', 'lag_3', 'lag_4', 'lag_5', 'lag_6', 'lag_7', 'rolling_mean', 'expanding_mean', 'time']]\n",
    "\n",
    "      all_pairs = pd.concat([all_pairs, currconv1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "cd38e54d",
   "metadata": {},
   "outputs": [],
   "source": [
    "CURRENCY_1 = ('SEK',)\n",
    "CURRENCY_2 = ('USD', 'EUR', 'JPY', 'GBP', 'AUD',)\n",
    "\n",
    "\n",
    "for c1 in CURRENCY_1:\n",
    "  for c2 in CURRENCY_2:\n",
    "    if c1 != c2:\n",
    "      currconv = app.get_currency_exchange_daily(c1, c2)\n",
    "      currconv1 = currconv[0]\n",
    "      currconv1['to symbol'] = c2\n",
    "      currconv1['from symbol'] = c1\n",
    "\n",
    "      currconv1.rename(columns={'1. open': 'open'}, inplace=True)\n",
    "      currconv1.rename(columns={'2. high': 'high'}, inplace=True)\n",
    "      currconv1.rename(columns={'3. low': 'low'}, inplace=True)\n",
    "      currconv1.rename(columns={'4. close': 'close'}, inplace=True)\n",
    "\n",
    "      pd.to_datetime(currconv1.index)\n",
    "      currconv1 = currconv1.sort_index()\n",
    "\n",
    "      currconv1['time'] = np.arange(len(currconv1.index))\n",
    "\n",
    "      currconv1['lag_1'] = currconv1['close'].shift(1)\n",
    "      currconv1['lag_2'] = currconv1['close'].shift(2)\n",
    "      currconv1['lag_3'] = currconv1['close'].shift(3)\n",
    "      currconv1['lag_4'] = currconv1['close'].shift(4)\n",
    "      currconv1['lag_5'] = currconv1['close'].shift(5)\n",
    "      currconv1['lag_6'] = currconv1['close'].shift(6)\n",
    "      currconv1['lag_7'] = currconv1['close'].shift(7)\n",
    "\n",
    "      currconv1['rolling_mean'] = currconv1['close'].rolling(window=7).mean()\n",
    "      currconv1['expanding_mean'] = currconv1['close'].expanding(2).mean()\n",
    "\n",
    "      currconv1 = currconv1[['from symbol', 'to symbol', 'open', 'high', 'low', 'close', 'lag_1', 'lag_2', 'lag_3', 'lag_4', 'lag_5', 'lag_6', 'lag_7', 'rolling_mean', 'expanding_mean', 'time']]\n",
    "\n",
    "      all_pairs = pd.concat([all_pairs, currconv1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "10d7c4e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "CURRENCY_1 = ('SEK',)\n",
    "CURRENCY_2 = ('CHF', 'CAD', 'HKD', 'SEK', 'NZD',)\n",
    "\n",
    "\n",
    "for c1 in CURRENCY_1:\n",
    "  for c2 in CURRENCY_2:\n",
    "    if c1 != c2:\n",
    "      currconv = app.get_currency_exchange_daily(c1, c2)\n",
    "      currconv1 = currconv[0]\n",
    "      currconv1['to symbol'] = c2\n",
    "      currconv1['from symbol'] = c1\n",
    "\n",
    "      currconv1.rename(columns={'1. open': 'open'}, inplace=True)\n",
    "      currconv1.rename(columns={'2. high': 'high'}, inplace=True)\n",
    "      currconv1.rename(columns={'3. low': 'low'}, inplace=True)\n",
    "      currconv1.rename(columns={'4. close': 'close'}, inplace=True)\n",
    "\n",
    "      pd.to_datetime(currconv1.index)\n",
    "      currconv1 = currconv1.sort_index()\n",
    "\n",
    "      currconv1['time'] = np.arange(len(currconv1.index))\n",
    "\n",
    "      currconv1['lag_1'] = currconv1['close'].shift(1)\n",
    "      currconv1['lag_2'] = currconv1['close'].shift(2)\n",
    "      currconv1['lag_3'] = currconv1['close'].shift(3)\n",
    "      currconv1['lag_4'] = currconv1['close'].shift(4)\n",
    "      currconv1['lag_5'] = currconv1['close'].shift(5)\n",
    "      currconv1['lag_6'] = currconv1['close'].shift(6)\n",
    "      currconv1['lag_7'] = currconv1['close'].shift(7)\n",
    "\n",
    "      currconv1['rolling_mean'] = currconv1['close'].rolling(window=7).mean()\n",
    "      currconv1['expanding_mean'] = currconv1['close'].expanding(2).mean()\n",
    "\n",
    "      currconv1 = currconv1[['from symbol', 'to symbol', 'open', 'high', 'low', 'close', 'lag_1', 'lag_2', 'lag_3', 'lag_4', 'lag_5', 'lag_6', 'lag_7', 'rolling_mean', 'expanding_mean', 'time']]\n",
    "\n",
    "      all_pairs = pd.concat([all_pairs, currconv1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "1d09bb9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "CURRENCY_1 = ('NZD',)\n",
    "CURRENCY_2 = ('USD', 'EUR', 'JPY', 'GBP', 'AUD',)\n",
    "\n",
    "\n",
    "for c1 in CURRENCY_1:\n",
    "  for c2 in CURRENCY_2:\n",
    "    if c1 != c2:\n",
    "      currconv = app.get_currency_exchange_daily(c1, c2)\n",
    "      currconv1 = currconv[0]\n",
    "      currconv1['to symbol'] = c2\n",
    "      currconv1['from symbol'] = c1\n",
    "\n",
    "      currconv1.rename(columns={'1. open': 'open'}, inplace=True)\n",
    "      currconv1.rename(columns={'2. high': 'high'}, inplace=True)\n",
    "      currconv1.rename(columns={'3. low': 'low'}, inplace=True)\n",
    "      currconv1.rename(columns={'4. close': 'close'}, inplace=True)\n",
    "\n",
    "      pd.to_datetime(currconv1.index)\n",
    "      currconv1 = currconv1.sort_index()\n",
    "\n",
    "      currconv1['time'] = np.arange(len(currconv1.index))\n",
    "\n",
    "      currconv1['lag_1'] = currconv1['close'].shift(1)\n",
    "      currconv1['lag_2'] = currconv1['close'].shift(2)\n",
    "      currconv1['lag_3'] = currconv1['close'].shift(3)\n",
    "      currconv1['lag_4'] = currconv1['close'].shift(4)\n",
    "      currconv1['lag_5'] = currconv1['close'].shift(5)\n",
    "      currconv1['lag_6'] = currconv1['close'].shift(6)\n",
    "      currconv1['lag_7'] = currconv1['close'].shift(7)\n",
    "\n",
    "      currconv1['rolling_mean'] = currconv1['close'].rolling(window=7).mean()\n",
    "      currconv1['expanding_mean'] = currconv1['close'].expanding(2).mean()\n",
    "\n",
    "      currconv1 = currconv1[['from symbol', 'to symbol', 'open', 'high', 'low', 'close', 'lag_1', 'lag_2', 'lag_3', 'lag_4', 'lag_5', 'lag_6', 'lag_7', 'rolling_mean', 'expanding_mean', 'time']]\n",
    "\n",
    "      all_pairs = pd.concat([all_pairs, currconv1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "35b434ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "CURRENCY_1 = ('NZD',)\n",
    "CURRENCY_2 = ('CHF', 'CAD', 'HKD', 'SEK', 'NZD',)\n",
    "\n",
    "\n",
    "for c1 in CURRENCY_1:\n",
    "  for c2 in CURRENCY_2:\n",
    "    if c1 != c2:\n",
    "      currconv = app.get_currency_exchange_daily(c1, c2)\n",
    "      currconv1 = currconv[0]\n",
    "      currconv1['to symbol'] = c2\n",
    "      currconv1['from symbol'] = c1\n",
    "\n",
    "      currconv1.rename(columns={'1. open': 'open'}, inplace=True)\n",
    "      currconv1.rename(columns={'2. high': 'high'}, inplace=True)\n",
    "      currconv1.rename(columns={'3. low': 'low'}, inplace=True)\n",
    "      currconv1.rename(columns={'4. close': 'close'}, inplace=True)\n",
    "\n",
    "      pd.to_datetime(currconv1.index)\n",
    "      currconv1 = currconv1.sort_index()\n",
    "\n",
    "      currconv1['time'] = np.arange(len(currconv1.index))\n",
    "\n",
    "      currconv1['lag_1'] = currconv1['close'].shift(1)\n",
    "      currconv1['lag_2'] = currconv1['close'].shift(2)\n",
    "      currconv1['lag_3'] = currconv1['close'].shift(3)\n",
    "      currconv1['lag_4'] = currconv1['close'].shift(4)\n",
    "      currconv1['lag_5'] = currconv1['close'].shift(5)\n",
    "      currconv1['lag_6'] = currconv1['close'].shift(6)\n",
    "      currconv1['lag_7'] = currconv1['close'].shift(7)\n",
    "\n",
    "      currconv1['rolling_mean'] = currconv1['close'].rolling(window=7).mean()\n",
    "      currconv1['expanding_mean'] = currconv1['close'].expanding(2).mean()\n",
    "\n",
    "      currconv1 = currconv1[['from symbol', 'to symbol', 'open', 'high', 'low', 'close', 'lag_1', 'lag_2', 'lag_3', 'lag_4', 'lag_5', 'lag_6', 'lag_7', 'rolling_mean', 'expanding_mean', 'time']]\n",
    "\n",
    "      all_pairs = pd.concat([all_pairs, currconv1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5abdd158",
   "metadata": {},
   "source": [
    "# Part Three\n",
    "Obtain and clean sentiment data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3651a0d3",
   "metadata": {},
   "source": [
    "* Create empty dataframe to concatenate to"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "b21fef40",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_sentiment = pd.DataFrame()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d1e3d11",
   "metadata": {},
   "source": [
    "* Request from API\n",
    "* Get json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "ed126080",
   "metadata": {},
   "outputs": [],
   "source": [
    "url2 = 'https://www.alphavantage.co/query?function=NEWS_SENTIMENT&tickers=forex:USD&from_date:20220901T0000&apikey={}'.format(ALPHA_VANTAGE_API_KEY)\n",
    "r2 = requests.get(url2)\n",
    "data2 = r2.json()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5978010",
   "metadata": {},
   "source": [
    "The data that was returned is very layered:\n",
    "* Convert to list\n",
    "* Pop unneeded items"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "0ad5ed03",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('relevance_score_definition',\n",
       " '0 < x <= 1, with a higher score indicating higher relevance.')"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "listsent = list(data2.items())\n",
    "\n",
    "listsent.pop(0)\n",
    "listsent.pop(0)\n",
    "listsent.pop(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "325c83a3",
   "metadata": {},
   "source": [
    "* Flatten list twice (I found this worked the best):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "769a26fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "flat_ls = []\n",
    "for i in listsent:\n",
    "    for j in i:\n",
    "        flat_ls.append(j)\n",
    " \n",
    "flat_ls.pop(0)\n",
    "\n",
    "flat_ls2 = []\n",
    "for i in flat_ls:\n",
    "    for j in i:\n",
    "        flat_ls2.append(j)\n",
    " \n",
    "dftest = pd.DataFrame(flat_ls2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "231b2da7",
   "metadata": {},
   "source": [
    "* Explode 'ticker sentiment' column:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "748cb429",
   "metadata": {},
   "outputs": [],
   "source": [
    "dftest = dftest.explode('ticker_sentiment')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "756b3619",
   "metadata": {},
   "source": [
    "* Delete unneeded columns\n",
    "* Reset index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "63b791e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "del dftest['summary']\n",
    "del dftest['banner_image']\n",
    "del dftest['category_within_source']\n",
    "del dftest['source_domain']\n",
    "del dftest['source']\n",
    "del dftest['topics']\n",
    "\n",
    "dftest = dftest.reset_index(inplace = False, drop = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1400fe05",
   "metadata": {},
   "source": [
    "Use a for loop to access dictionary inside 'ticker sentiment' column:\n",
    "* Even though the API returns data for the specified ticker, it also returns duplicate rows of the same data for other tickers that the same news article also applies to\n",
    "* I want to keep the data as organized as possible and do not want to deal with messy duplicates later after requesting from the API for other tickers\n",
    "* The for loop checks if the ticker equals the specified currency - if not, the row is dropped"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "b0f51ffe",
   "metadata": {},
   "outputs": [],
   "source": [
    "drop_values = []\n",
    "for k, v in dftest['ticker_sentiment'].iteritems():\n",
    "    for j, i in v.items():\n",
    "        if j == 'ticker':\n",
    "            if i != 'FOREX:USD':\n",
    "                drop_values.append(k)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e84f1c9",
   "metadata": {},
   "source": [
    "* Create new dataframe from list\n",
    "* Sort values by overall sentiment score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "833a20de",
   "metadata": {},
   "outputs": [],
   "source": [
    "usdforexsentiment = dftest.drop(index=drop_values)\n",
    "usdforexsentiment = usdforexsentiment.sort_values(by='overall_sentiment_score', ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d5ba381",
   "metadata": {},
   "source": [
    "* Add a column for symbol\n",
    "* Set index to symbol"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "4386efcf",
   "metadata": {},
   "outputs": [],
   "source": [
    "usdforexsentiment['symbol'] = 'USD'\n",
    "usdforexsentiment.set_index('symbol', inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8fe114b0",
   "metadata": {},
   "source": [
    "* Concatenate to all_sentiment dataframe\n",
    "* Check individual dataframe head to confirm everything worked"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "a7d77424",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>url</th>\n",
       "      <th>time_published</th>\n",
       "      <th>authors</th>\n",
       "      <th>overall_sentiment_score</th>\n",
       "      <th>overall_sentiment_label</th>\n",
       "      <th>ticker_sentiment</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>symbol</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>USD</th>\n",
       "      <td>Mitsubishi raises profit forecast on higher co...</td>\n",
       "      <td>https://www.reuters.com/business/autos-transpo...</td>\n",
       "      <td>20221108T121400</td>\n",
       "      <td>[Reuters]</td>\n",
       "      <td>0.335897</td>\n",
       "      <td>Somewhat-Bullish</td>\n",
       "      <td>{'ticker': 'FOREX:USD', 'relevance_score': '0....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>USD</th>\n",
       "      <td>ETF Asset Report of October</td>\n",
       "      <td>https://www.zacks.com/stock/news/2015630/etf-a...</td>\n",
       "      <td>20221108T180000</td>\n",
       "      <td>[Zacks Investment Research]</td>\n",
       "      <td>0.334772</td>\n",
       "      <td>Somewhat-Bullish</td>\n",
       "      <td>{'ticker': 'FOREX:USD', 'relevance_score': '0....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>USD</th>\n",
       "      <td>Ethereum-Based Prediction Market Shows Red Wav...</td>\n",
       "      <td>https://decrypt.co/113844/ethereum-based-predi...</td>\n",
       "      <td>20221108T154155</td>\n",
       "      <td>[Decrypt / Ben Munster]</td>\n",
       "      <td>0.306016</td>\n",
       "      <td>Somewhat-Bullish</td>\n",
       "      <td>{'ticker': 'FOREX:USD', 'relevance_score': '0....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>USD</th>\n",
       "      <td>1 in 5 College Students in the US Has Used The...</td>\n",
       "      <td>https://www.investorideas.com/news/2022/crypto...</td>\n",
       "      <td>20221108T154049</td>\n",
       "      <td>[]</td>\n",
       "      <td>0.301102</td>\n",
       "      <td>Somewhat-Bullish</td>\n",
       "      <td>{'ticker': 'FOREX:USD', 'relevance_score': '0....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>USD</th>\n",
       "      <td>These 3 European Companies Could See Their Div...</td>\n",
       "      <td>https://www.benzinga.com/news/large-cap/22/11/...</td>\n",
       "      <td>20221108T165857</td>\n",
       "      <td>[Robert Kuczmarski]</td>\n",
       "      <td>0.256880</td>\n",
       "      <td>Somewhat-Bullish</td>\n",
       "      <td>{'ticker': 'FOREX:USD', 'relevance_score': '0....</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    title  \\\n",
       "symbol                                                      \n",
       "USD     Mitsubishi raises profit forecast on higher co...   \n",
       "USD                           ETF Asset Report of October   \n",
       "USD     Ethereum-Based Prediction Market Shows Red Wav...   \n",
       "USD     1 in 5 College Students in the US Has Used The...   \n",
       "USD     These 3 European Companies Could See Their Div...   \n",
       "\n",
       "                                                      url   time_published  \\\n",
       "symbol                                                                       \n",
       "USD     https://www.reuters.com/business/autos-transpo...  20221108T121400   \n",
       "USD     https://www.zacks.com/stock/news/2015630/etf-a...  20221108T180000   \n",
       "USD     https://decrypt.co/113844/ethereum-based-predi...  20221108T154155   \n",
       "USD     https://www.investorideas.com/news/2022/crypto...  20221108T154049   \n",
       "USD     https://www.benzinga.com/news/large-cap/22/11/...  20221108T165857   \n",
       "\n",
       "                            authors  overall_sentiment_score  \\\n",
       "symbol                                                         \n",
       "USD                       [Reuters]                 0.335897   \n",
       "USD     [Zacks Investment Research]                 0.334772   \n",
       "USD         [Decrypt / Ben Munster]                 0.306016   \n",
       "USD                              []                 0.301102   \n",
       "USD             [Robert Kuczmarski]                 0.256880   \n",
       "\n",
       "       overall_sentiment_label  \\\n",
       "symbol                           \n",
       "USD           Somewhat-Bullish   \n",
       "USD           Somewhat-Bullish   \n",
       "USD           Somewhat-Bullish   \n",
       "USD           Somewhat-Bullish   \n",
       "USD           Somewhat-Bullish   \n",
       "\n",
       "                                         ticker_sentiment  \n",
       "symbol                                                     \n",
       "USD     {'ticker': 'FOREX:USD', 'relevance_score': '0....  \n",
       "USD     {'ticker': 'FOREX:USD', 'relevance_score': '0....  \n",
       "USD     {'ticker': 'FOREX:USD', 'relevance_score': '0....  \n",
       "USD     {'ticker': 'FOREX:USD', 'relevance_score': '0....  \n",
       "USD     {'ticker': 'FOREX:USD', 'relevance_score': '0....  "
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_sentiment = pd.concat([all_sentiment, usdforexsentiment])\n",
    "\n",
    "usdforexsentiment.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d96c907d",
   "metadata": {},
   "source": [
    "* Find mean of overall sentiment score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "ca2f2d8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "mean = usdforexsentiment['overall_sentiment_score'].mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "222ea5a2",
   "metadata": {},
   "source": [
    "* Create empty column in all_pairs dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "487142dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_pairs['sentiment_score'] = ''"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9a8ab5b",
   "metadata": {},
   "source": [
    "Repeat for other currencies:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "db15c5d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "url2 = 'https://www.alphavantage.co/query?function=NEWS_SENTIMENT&tickers=forex:EUR&from_date:20220901T0000&apikey={}'.format(ALPHA_VANTAGE_API_KEY)\n",
    "r2 = requests.get(url2)\n",
    "data2 = r2.json()\n",
    "\n",
    "listsent = list(data2.items())\n",
    "\n",
    "listsent.pop(0)\n",
    "listsent.pop(0)\n",
    "listsent.pop(0)\n",
    "\n",
    "flat_ls = []\n",
    "for i in listsent:\n",
    "    for j in i:\n",
    "        flat_ls.append(j)\n",
    " \n",
    "flat_ls.pop(0)\n",
    "\n",
    "flat_ls2 = []\n",
    "for i in flat_ls:\n",
    "    for j in i:\n",
    "        flat_ls2.append(j)\n",
    " \n",
    "dftest = pd.DataFrame(flat_ls2)\n",
    "\n",
    "dftest = dftest.explode('ticker_sentiment')\n",
    "\n",
    "del dftest['summary']\n",
    "del dftest['banner_image']\n",
    "del dftest['category_within_source']\n",
    "del dftest['source_domain']\n",
    "del dftest['source']\n",
    "del dftest['topics']\n",
    "\n",
    "dftest = dftest.reset_index(inplace = False, drop = True)\n",
    "\n",
    "drop_values = []\n",
    "for k, v in dftest['ticker_sentiment'].iteritems():\n",
    "    for j, i in v.items():\n",
    "        if j == 'ticker':\n",
    "            if i != 'FOREX:EUR':\n",
    "                drop_values.append(k)\n",
    "\n",
    "eurforexsentiment = dftest.drop(index=drop_values)\n",
    "eurforexsentiment = eurforexsentiment.sort_values(by='overall_sentiment_score', ascending=False)\n",
    "\n",
    "eurforexsentiment['symbol'] = 'EUR'\n",
    "eurforexsentiment.set_index('symbol', inplace=True)\n",
    "\n",
    "all_sentiment = pd.concat([all_sentiment, eurforexsentiment])\n",
    "\n",
    "eurmean = eurforexsentiment['overall_sentiment_score'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "50cc9c7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "url2 = 'https://www.alphavantage.co/query?function=NEWS_SENTIMENT&tickers=forex:JPY&from_date:20220901T0000&apikey={}'.format(ALPHA_VANTAGE_API_KEY)\n",
    "r2 = requests.get(url2)\n",
    "data2 = r2.json()\n",
    "\n",
    "listsent = list(data2.items())\n",
    "\n",
    "listsent.pop(0)\n",
    "listsent.pop(0)\n",
    "listsent.pop(0)\n",
    "\n",
    "flat_ls = []\n",
    "for i in listsent:\n",
    "    for j in i:\n",
    "        flat_ls.append(j)\n",
    " \n",
    "flat_ls.pop(0)\n",
    "\n",
    "flat_ls2 = []\n",
    "for i in flat_ls:\n",
    "    for j in i:\n",
    "        flat_ls2.append(j)\n",
    " \n",
    "dftest = pd.DataFrame(flat_ls2)\n",
    "\n",
    "dftest = dftest.explode('ticker_sentiment')\n",
    "\n",
    "del dftest['summary']\n",
    "del dftest['banner_image']\n",
    "del dftest['category_within_source']\n",
    "del dftest['source_domain']\n",
    "del dftest['source']\n",
    "del dftest['topics']\n",
    "\n",
    "dftest = dftest.reset_index(inplace = False, drop = True)\n",
    "\n",
    "drop_values = []\n",
    "for k, v in dftest['ticker_sentiment'].iteritems():\n",
    "    for j, i in v.items():\n",
    "        if j == 'ticker':\n",
    "            if i != 'FOREX:JPY':\n",
    "                drop_values.append(k)\n",
    "\n",
    "jpyforexsentiment = dftest.drop(index=drop_values)\n",
    "jpyforexsentiment = jpyforexsentiment.sort_values(by='overall_sentiment_score', ascending=False)\n",
    "\n",
    "jpyforexsentiment['symbol'] = 'JPY'\n",
    "jpyforexsentiment.set_index('symbol', inplace=True)\n",
    "\n",
    "all_sentiment = pd.concat([all_sentiment, jpyforexsentiment])\n",
    "\n",
    "jpymean = jpyforexsentiment['overall_sentiment_score'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "31c9fd70",
   "metadata": {},
   "outputs": [],
   "source": [
    "url2 = 'https://www.alphavantage.co/query?function=NEWS_SENTIMENT&tickers=forex:GBP&from_date:20220901T0000&apikey={}'.format(ALPHA_VANTAGE_API_KEY)\n",
    "r2 = requests.get(url2)\n",
    "data2 = r2.json()\n",
    "\n",
    "listsent = list(data2.items())\n",
    "\n",
    "listsent.pop(0)\n",
    "listsent.pop(0)\n",
    "listsent.pop(0)\n",
    "\n",
    "flat_ls = []\n",
    "for i in listsent:\n",
    "    for j in i:\n",
    "        flat_ls.append(j)\n",
    " \n",
    "flat_ls.pop(0)\n",
    "\n",
    "flat_ls2 = []\n",
    "for i in flat_ls:\n",
    "    for j in i:\n",
    "        flat_ls2.append(j)\n",
    " \n",
    "dftest = pd.DataFrame(flat_ls2)\n",
    "\n",
    "dftest = dftest.explode('ticker_sentiment')\n",
    "\n",
    "del dftest['summary']\n",
    "del dftest['banner_image']\n",
    "del dftest['category_within_source']\n",
    "del dftest['source_domain']\n",
    "del dftest['source']\n",
    "del dftest['topics']\n",
    "\n",
    "dftest = dftest.reset_index(inplace = False, drop = True)\n",
    "\n",
    "drop_values = []\n",
    "for k, v in dftest['ticker_sentiment'].iteritems():\n",
    "    for j, i in v.items():\n",
    "        if j == 'ticker':\n",
    "            if i != 'FOREX:GBP':\n",
    "                drop_values.append(k)\n",
    "\n",
    "gbpforexsentiment = dftest.drop(index=drop_values)\n",
    "gbpforexsentiment = gbpforexsentiment.sort_values(by='overall_sentiment_score', ascending=False)\n",
    "\n",
    "gbpforexsentiment['symbol'] = 'GBP'\n",
    "gbpforexsentiment.set_index('symbol', inplace=True)\n",
    "                            \n",
    "all_sentiment = pd.concat([all_sentiment, gbpforexsentiment])\n",
    "\n",
    "gbpmean = gbpforexsentiment['overall_sentiment_score'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "50ee167e",
   "metadata": {},
   "outputs": [],
   "source": [
    "url2 = 'https://www.alphavantage.co/query?function=NEWS_SENTIMENT&tickers=forex:AUD&from_date:20220901T0000&apikey={}'.format(ALPHA_VANTAGE_API_KEY)\n",
    "r2 = requests.get(url2)\n",
    "data2 = r2.json()\n",
    "\n",
    "listsent = list(data2.items())\n",
    "\n",
    "listsent.pop(0)\n",
    "listsent.pop(0)\n",
    "listsent.pop(0)\n",
    "\n",
    "flat_ls = []\n",
    "for i in listsent:\n",
    "    for j in i:\n",
    "        flat_ls.append(j)\n",
    " \n",
    "flat_ls.pop(0)\n",
    "\n",
    "flat_ls2 = []\n",
    "for i in flat_ls:\n",
    "    for j in i:\n",
    "        flat_ls2.append(j)\n",
    " \n",
    "dftest = pd.DataFrame(flat_ls2)\n",
    "\n",
    "dftest = dftest.explode('ticker_sentiment')\n",
    "\n",
    "del dftest['summary']\n",
    "del dftest['banner_image']\n",
    "del dftest['category_within_source']\n",
    "del dftest['source_domain']\n",
    "del dftest['source']\n",
    "del dftest['topics']\n",
    "\n",
    "dftest = dftest.reset_index(inplace = False, drop = True)\n",
    "\n",
    "drop_values = []\n",
    "for k, v in dftest['ticker_sentiment'].iteritems():\n",
    "    for j, i in v.items():\n",
    "        if j == 'ticker':\n",
    "            if i != 'FOREX:AUD':\n",
    "                drop_values.append(k)\n",
    "\n",
    "audforexsentiment = dftest.drop(index=drop_values)\n",
    "audforexsentiment = audforexsentiment.sort_values(by='overall_sentiment_score', ascending=False)\n",
    "\n",
    "audforexsentiment['symbol'] = 'AUD'\n",
    "audforexsentiment.set_index('symbol', inplace=True)\n",
    "\n",
    "all_sentiment = pd.concat([all_sentiment, audforexsentiment])\n",
    "\n",
    "audmean = audforexsentiment['overall_sentiment_score'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "57b15b48",
   "metadata": {},
   "outputs": [],
   "source": [
    "url2 = 'https://www.alphavantage.co/query?function=NEWS_SENTIMENT&tickers=forex:CHF&from_date:20220901T0000&apikey={}'.format(ALPHA_VANTAGE_API_KEY)\n",
    "r2 = requests.get(url2)\n",
    "data2 = r2.json()\n",
    "\n",
    "listsent = list(data2.items())\n",
    "\n",
    "listsent.pop(0)\n",
    "listsent.pop(0)\n",
    "listsent.pop(0)\n",
    "\n",
    "flat_ls = []\n",
    "for i in listsent:\n",
    "    for j in i:\n",
    "        flat_ls.append(j)\n",
    " \n",
    "flat_ls.pop(0)\n",
    "\n",
    "flat_ls2 = []\n",
    "for i in flat_ls:\n",
    "    for j in i:\n",
    "        flat_ls2.append(j)\n",
    " \n",
    "dftest = pd.DataFrame(flat_ls2)\n",
    "\n",
    "dftest = dftest.explode('ticker_sentiment')\n",
    "\n",
    "del dftest['summary']\n",
    "del dftest['banner_image']\n",
    "del dftest['category_within_source']\n",
    "del dftest['source_domain']\n",
    "del dftest['source']\n",
    "del dftest['topics']\n",
    "\n",
    "dftest = dftest.reset_index(inplace = False, drop = True)\n",
    "\n",
    "drop_values = []\n",
    "for k, v in dftest['ticker_sentiment'].iteritems():\n",
    "    for j, i in v.items():\n",
    "        if j == 'ticker':\n",
    "            if i != 'FOREX:CHF':\n",
    "                drop_values.append(k)\n",
    "\n",
    "chfforexsentiment = dftest.drop(index=drop_values)\n",
    "chfforexsentiment = chfforexsentiment.sort_values(by='overall_sentiment_score', ascending=False)\n",
    "\n",
    "chfforexsentiment['symbol'] = 'CHF'\n",
    "chfforexsentiment.set_index('symbol', inplace=True)\n",
    "\n",
    "all_sentiment = pd.concat([all_sentiment, chfforexsentiment])\n",
    "\n",
    "chfmean = chfforexsentiment['overall_sentiment_score'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "e7a8cc3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "url2 = 'https://www.alphavantage.co/query?function=NEWS_SENTIMENT&tickers=forex:CAD&from_date:20220901T0000&apikey={}'.format(ALPHA_VANTAGE_API_KEY)\n",
    "r2 = requests.get(url2)\n",
    "data2 = r2.json()\n",
    "\n",
    "listsent = list(data2.items())\n",
    "\n",
    "listsent.pop(0)\n",
    "listsent.pop(0)\n",
    "listsent.pop(0)\n",
    "\n",
    "flat_ls = []\n",
    "for i in listsent:\n",
    "    for j in i:\n",
    "        flat_ls.append(j)\n",
    " \n",
    "flat_ls.pop(0)\n",
    "\n",
    "flat_ls2 = []\n",
    "for i in flat_ls:\n",
    "    for j in i:\n",
    "        flat_ls2.append(j)\n",
    " \n",
    "dftest = pd.DataFrame(flat_ls2)\n",
    "\n",
    "dftest = dftest.explode('ticker_sentiment')\n",
    "\n",
    "del dftest['summary']\n",
    "del dftest['banner_image']\n",
    "del dftest['category_within_source']\n",
    "del dftest['source_domain']\n",
    "del dftest['source']\n",
    "del dftest['topics']\n",
    "\n",
    "dftest = dftest.reset_index(inplace = False, drop = True)\n",
    "\n",
    "drop_values = []\n",
    "for k, v in dftest['ticker_sentiment'].iteritems():\n",
    "    for j, i in v.items():\n",
    "        if j == 'ticker':\n",
    "            if i != 'FOREX:CAD':\n",
    "                drop_values.append(k)\n",
    "\n",
    "cadforexsentiment = dftest.drop(index=drop_values)\n",
    "cadforexsentiment = cadforexsentiment.sort_values(by='overall_sentiment_score', ascending=False)\n",
    "\n",
    "cadforexsentiment['symbol'] = 'CAD'\n",
    "cadforexsentiment.set_index('symbol', inplace=True)\n",
    "\n",
    "all_sentiment = pd.concat([all_sentiment, cadforexsentiment])\n",
    "\n",
    "cadmean = cadforexsentiment['overall_sentiment_score'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "92fd9576",
   "metadata": {},
   "outputs": [],
   "source": [
    "url2 = 'https://www.alphavantage.co/query?function=NEWS_SENTIMENT&tickers=forex:HKD&from_date:20220901T0000&apikey={}'.format(ALPHA_VANTAGE_API_KEY)\n",
    "r2 = requests.get(url2)\n",
    "data2 = r2.json()\n",
    "\n",
    "listsent = list(data2.items())\n",
    "\n",
    "listsent.pop(0)\n",
    "listsent.pop(0)\n",
    "listsent.pop(0)\n",
    "\n",
    "flat_ls = []\n",
    "for i in listsent:\n",
    "    for j in i:\n",
    "        flat_ls.append(j)\n",
    " \n",
    "flat_ls.pop(0)\n",
    "\n",
    "flat_ls2 = []\n",
    "for i in flat_ls:\n",
    "    for j in i:\n",
    "        flat_ls2.append(j)\n",
    " \n",
    "dftest = pd.DataFrame(flat_ls2)\n",
    "\n",
    "dftest = dftest.explode('ticker_sentiment')\n",
    "\n",
    "del dftest['summary']\n",
    "del dftest['banner_image']\n",
    "del dftest['category_within_source']\n",
    "del dftest['source_domain']\n",
    "del dftest['source']\n",
    "del dftest['topics']\n",
    "\n",
    "dftest = dftest.reset_index(inplace = False, drop = True)\n",
    "\n",
    "drop_values = []\n",
    "for k, v in dftest['ticker_sentiment'].iteritems():\n",
    "    for j, i in v.items():\n",
    "        if j == 'ticker':\n",
    "            if i != 'FOREX:HKD':\n",
    "                drop_values.append(k)\n",
    "\n",
    "hkdforexsentiment = dftest.drop(index=drop_values)\n",
    "hkdforexsentiment = hkdforexsentiment.sort_values(by='overall_sentiment_score', ascending=False)\n",
    "\n",
    "hkdforexsentiment['symbol'] = 'HKD'\n",
    "hkdforexsentiment.set_index('symbol', inplace=True)\n",
    "\n",
    "all_sentiment = pd.concat([all_sentiment, hkdforexsentiment])\n",
    "\n",
    "hkdmean = hkdforexsentiment['overall_sentiment_score'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "c9862fec",
   "metadata": {},
   "outputs": [],
   "source": [
    "url2 = 'https://www.alphavantage.co/query?function=NEWS_SENTIMENT&tickers=forex:SEK&from_date:20220901T0000&apikey={}'.format(ALPHA_VANTAGE_API_KEY)\n",
    "r2 = requests.get(url2)\n",
    "data2 = r2.json()\n",
    "\n",
    "listsent = list(data2.items())\n",
    "\n",
    "listsent.pop(0)\n",
    "listsent.pop(0)\n",
    "listsent.pop(0)\n",
    "\n",
    "flat_ls = []\n",
    "for i in listsent:\n",
    "    for j in i:\n",
    "        flat_ls.append(j)\n",
    " \n",
    "flat_ls.pop(0)\n",
    "\n",
    "flat_ls2 = []\n",
    "for i in flat_ls:\n",
    "    for j in i:\n",
    "        flat_ls2.append(j)\n",
    " \n",
    "dftest = pd.DataFrame(flat_ls2)\n",
    "\n",
    "dftest = dftest.explode('ticker_sentiment')\n",
    "\n",
    "del dftest['summary']\n",
    "del dftest['banner_image']\n",
    "del dftest['category_within_source']\n",
    "del dftest['source_domain']\n",
    "del dftest['source']\n",
    "del dftest['topics']\n",
    "\n",
    "dftest = dftest.reset_index(inplace = False, drop = True)\n",
    "\n",
    "drop_values = []\n",
    "for k, v in dftest['ticker_sentiment'].iteritems():\n",
    "    for j, i in v.items():\n",
    "        if j == 'ticker':\n",
    "            if i != 'FOREX:SEK':\n",
    "                drop_values.append(k)\n",
    "\n",
    "sekforexsentiment = dftest.drop(index=drop_values)\n",
    "sekforexsentiment = sekforexsentiment.sort_values(by='overall_sentiment_score', ascending=False)\n",
    "\n",
    "sekforexsentiment['symbol'] = 'SEK'\n",
    "sekforexsentiment.set_index('symbol', inplace=True)\n",
    "\n",
    "all_sentiment = pd.concat([all_sentiment, sekforexsentiment])\n",
    "\n",
    "sekmean = sekforexsentiment['overall_sentiment_score'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "d55c4ba3",
   "metadata": {},
   "outputs": [],
   "source": [
    "url2 = 'https://www.alphavantage.co/query?function=NEWS_SENTIMENT&tickers=forex:NZD&from_date:20220901T0000&apikey={}'.format(ALPHA_VANTAGE_API_KEY)\n",
    "r2 = requests.get(url2)\n",
    "data2 = r2.json()\n",
    "\n",
    "listsent = list(data2.items())\n",
    "\n",
    "listsent.pop(0)\n",
    "listsent.pop(0)\n",
    "listsent.pop(0)\n",
    "\n",
    "flat_ls = []\n",
    "for i in listsent:\n",
    "    for j in i:\n",
    "        flat_ls.append(j)\n",
    " \n",
    "flat_ls.pop(0)\n",
    "\n",
    "flat_ls2 = []\n",
    "for i in flat_ls:\n",
    "    for j in i:\n",
    "        flat_ls2.append(j)\n",
    " \n",
    "dftest = pd.DataFrame(flat_ls2)\n",
    "\n",
    "dftest = dftest.explode('ticker_sentiment')\n",
    "\n",
    "del dftest['summary']\n",
    "del dftest['banner_image']\n",
    "del dftest['category_within_source']\n",
    "del dftest['source_domain']\n",
    "del dftest['source']\n",
    "del dftest['topics']\n",
    "\n",
    "dftest = dftest.reset_index(inplace = False, drop = True)\n",
    "\n",
    "drop_values = []\n",
    "for k, v in dftest['ticker_sentiment'].iteritems():\n",
    "    for j, i in v.items():\n",
    "        if j == 'ticker':\n",
    "            if i != 'FOREX:NZD':\n",
    "                drop_values.append(k)\n",
    "\n",
    "nzdforexsentiment = dftest.drop(index=drop_values)\n",
    "nzdforexsentiment = nzdforexsentiment.sort_values(by='overall_sentiment_score', ascending=False)\n",
    "\n",
    "nzdforexsentiment['symbol'] = 'NZD'\n",
    "nzdforexsentiment.set_index('symbol', inplace=True)\n",
    "\n",
    "all_sentiment = pd.concat([all_sentiment, nzdforexsentiment])\n",
    "\n",
    "nzdmean = nzdforexsentiment['overall_sentiment_score'].mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "195d5ba6",
   "metadata": {},
   "source": [
    "Save all_sentiment to pickle:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "4346e94b",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_sentiment.to_pickle('all_sentiment.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d2258bd",
   "metadata": {},
   "source": [
    "* Use a for loop to apply sentiment score mean to sentiment score column in all_pairs:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "efb86fe8",
   "metadata": {},
   "outputs": [],
   "source": [
    "for symbol in range(len(all_pairs['to symbol'])):\n",
    "    all_pairs.loc[(all_pairs['to symbol'] == 'USD'), 'sentiment_score'] = mean\n",
    "    all_pairs.loc[(all_pairs['to symbol'] == 'EUR'), 'sentiment_score'] = eurmean\n",
    "    all_pairs.loc[(all_pairs['to symbol'] == 'JPY'), 'sentiment_score'] = jpymean\n",
    "    all_pairs.loc[(all_pairs['to symbol'] == 'GBP'), 'sentiment_score'] = gbpmean\n",
    "    all_pairs.loc[(all_pairs['to symbol'] == 'AUD'), 'sentiment_score'] = audmean\n",
    "    all_pairs.loc[(all_pairs['to symbol'] == 'CHF'), 'sentiment_score'] = chfmean\n",
    "    all_pairs.loc[(all_pairs['to symbol'] == 'CAD'), 'sentiment_score'] = cadmean\n",
    "    all_pairs.loc[(all_pairs['to symbol'] == 'HKD'), 'sentiment_score'] = hkdmean\n",
    "    all_pairs.loc[(all_pairs['to symbol'] == 'SEK'), 'sentiment_score'] = sekmean\n",
    "    all_pairs.loc[(all_pairs['to symbol'] == 'NZD'), 'sentiment_score'] = nzdmean"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59a2eaa7",
   "metadata": {},
   "source": [
    "View all_pairs:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "a768ba38",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>from symbol</th>\n",
       "      <th>to symbol</th>\n",
       "      <th>open</th>\n",
       "      <th>high</th>\n",
       "      <th>low</th>\n",
       "      <th>close</th>\n",
       "      <th>lag_1</th>\n",
       "      <th>lag_2</th>\n",
       "      <th>lag_3</th>\n",
       "      <th>lag_4</th>\n",
       "      <th>lag_5</th>\n",
       "      <th>lag_6</th>\n",
       "      <th>lag_7</th>\n",
       "      <th>rolling_mean</th>\n",
       "      <th>expanding_mean</th>\n",
       "      <th>time</th>\n",
       "      <th>sentiment_score</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2022-06-22</th>\n",
       "      <td>USD</td>\n",
       "      <td>EUR</td>\n",
       "      <td>0.9489</td>\n",
       "      <td>0.9547</td>\n",
       "      <td>0.9426</td>\n",
       "      <td>0.9462</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0.092788</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-06-23</th>\n",
       "      <td>USD</td>\n",
       "      <td>EUR</td>\n",
       "      <td>0.9460</td>\n",
       "      <td>0.9536</td>\n",
       "      <td>0.9449</td>\n",
       "      <td>0.9499</td>\n",
       "      <td>0.9462</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.948050</td>\n",
       "      <td>1</td>\n",
       "      <td>0.092788</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-06-24</th>\n",
       "      <td>USD</td>\n",
       "      <td>EUR</td>\n",
       "      <td>0.9501</td>\n",
       "      <td>0.9509</td>\n",
       "      <td>0.9459</td>\n",
       "      <td>0.9471</td>\n",
       "      <td>0.9499</td>\n",
       "      <td>0.9462</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.947733</td>\n",
       "      <td>2</td>\n",
       "      <td>0.092788</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-06-27</th>\n",
       "      <td>USD</td>\n",
       "      <td>EUR</td>\n",
       "      <td>0.9470</td>\n",
       "      <td>0.9476</td>\n",
       "      <td>0.9418</td>\n",
       "      <td>0.9446</td>\n",
       "      <td>0.9471</td>\n",
       "      <td>0.9499</td>\n",
       "      <td>0.9462</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.946950</td>\n",
       "      <td>3</td>\n",
       "      <td>0.092788</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-06-28</th>\n",
       "      <td>USD</td>\n",
       "      <td>EUR</td>\n",
       "      <td>0.9445</td>\n",
       "      <td>0.9518</td>\n",
       "      <td>0.9427</td>\n",
       "      <td>0.9501</td>\n",
       "      <td>0.9446</td>\n",
       "      <td>0.9471</td>\n",
       "      <td>0.9499</td>\n",
       "      <td>0.9462</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.947580</td>\n",
       "      <td>4</td>\n",
       "      <td>0.092788</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-06-29</th>\n",
       "      <td>USD</td>\n",
       "      <td>EUR</td>\n",
       "      <td>0.9501</td>\n",
       "      <td>0.9580</td>\n",
       "      <td>0.9488</td>\n",
       "      <td>0.9575</td>\n",
       "      <td>0.9501</td>\n",
       "      <td>0.9446</td>\n",
       "      <td>0.9471</td>\n",
       "      <td>0.9499</td>\n",
       "      <td>0.9462</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.949233</td>\n",
       "      <td>5</td>\n",
       "      <td>0.092788</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-06-30</th>\n",
       "      <td>USD</td>\n",
       "      <td>EUR</td>\n",
       "      <td>0.9576</td>\n",
       "      <td>0.9628</td>\n",
       "      <td>0.9533</td>\n",
       "      <td>0.9540</td>\n",
       "      <td>0.9575</td>\n",
       "      <td>0.9501</td>\n",
       "      <td>0.9446</td>\n",
       "      <td>0.9471</td>\n",
       "      <td>0.9499</td>\n",
       "      <td>0.9462</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.949914</td>\n",
       "      <td>0.949914</td>\n",
       "      <td>6</td>\n",
       "      <td>0.092788</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-07-01</th>\n",
       "      <td>USD</td>\n",
       "      <td>EUR</td>\n",
       "      <td>0.9537</td>\n",
       "      <td>0.9641</td>\n",
       "      <td>0.9537</td>\n",
       "      <td>0.9591</td>\n",
       "      <td>0.9540</td>\n",
       "      <td>0.9575</td>\n",
       "      <td>0.9501</td>\n",
       "      <td>0.9446</td>\n",
       "      <td>0.9471</td>\n",
       "      <td>0.9499</td>\n",
       "      <td>0.9462</td>\n",
       "      <td>0.951757</td>\n",
       "      <td>0.951063</td>\n",
       "      <td>7</td>\n",
       "      <td>0.092788</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-07-04</th>\n",
       "      <td>USD</td>\n",
       "      <td>EUR</td>\n",
       "      <td>0.9592</td>\n",
       "      <td>0.9597</td>\n",
       "      <td>0.9556</td>\n",
       "      <td>0.9593</td>\n",
       "      <td>0.9591</td>\n",
       "      <td>0.9540</td>\n",
       "      <td>0.9575</td>\n",
       "      <td>0.9501</td>\n",
       "      <td>0.9446</td>\n",
       "      <td>0.9471</td>\n",
       "      <td>0.9499</td>\n",
       "      <td>0.953100</td>\n",
       "      <td>0.951978</td>\n",
       "      <td>8</td>\n",
       "      <td>0.092788</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-07-05</th>\n",
       "      <td>USD</td>\n",
       "      <td>EUR</td>\n",
       "      <td>0.9590</td>\n",
       "      <td>0.9768</td>\n",
       "      <td>0.9569</td>\n",
       "      <td>0.9739</td>\n",
       "      <td>0.9593</td>\n",
       "      <td>0.9591</td>\n",
       "      <td>0.9540</td>\n",
       "      <td>0.9575</td>\n",
       "      <td>0.9501</td>\n",
       "      <td>0.9446</td>\n",
       "      <td>0.9471</td>\n",
       "      <td>0.956929</td>\n",
       "      <td>0.954170</td>\n",
       "      <td>9</td>\n",
       "      <td>0.092788</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           from symbol to symbol    open    high     low   close   lag_1  \\\n",
       "date                                                                       \n",
       "2022-06-22         USD       EUR  0.9489  0.9547  0.9426  0.9462     NaN   \n",
       "2022-06-23         USD       EUR  0.9460  0.9536  0.9449  0.9499  0.9462   \n",
       "2022-06-24         USD       EUR  0.9501  0.9509  0.9459  0.9471  0.9499   \n",
       "2022-06-27         USD       EUR  0.9470  0.9476  0.9418  0.9446  0.9471   \n",
       "2022-06-28         USD       EUR  0.9445  0.9518  0.9427  0.9501  0.9446   \n",
       "2022-06-29         USD       EUR  0.9501  0.9580  0.9488  0.9575  0.9501   \n",
       "2022-06-30         USD       EUR  0.9576  0.9628  0.9533  0.9540  0.9575   \n",
       "2022-07-01         USD       EUR  0.9537  0.9641  0.9537  0.9591  0.9540   \n",
       "2022-07-04         USD       EUR  0.9592  0.9597  0.9556  0.9593  0.9591   \n",
       "2022-07-05         USD       EUR  0.9590  0.9768  0.9569  0.9739  0.9593   \n",
       "\n",
       "             lag_2   lag_3   lag_4   lag_5   lag_6   lag_7  rolling_mean  \\\n",
       "date                                                                       \n",
       "2022-06-22     NaN     NaN     NaN     NaN     NaN     NaN           NaN   \n",
       "2022-06-23     NaN     NaN     NaN     NaN     NaN     NaN           NaN   \n",
       "2022-06-24  0.9462     NaN     NaN     NaN     NaN     NaN           NaN   \n",
       "2022-06-27  0.9499  0.9462     NaN     NaN     NaN     NaN           NaN   \n",
       "2022-06-28  0.9471  0.9499  0.9462     NaN     NaN     NaN           NaN   \n",
       "2022-06-29  0.9446  0.9471  0.9499  0.9462     NaN     NaN           NaN   \n",
       "2022-06-30  0.9501  0.9446  0.9471  0.9499  0.9462     NaN      0.949914   \n",
       "2022-07-01  0.9575  0.9501  0.9446  0.9471  0.9499  0.9462      0.951757   \n",
       "2022-07-04  0.9540  0.9575  0.9501  0.9446  0.9471  0.9499      0.953100   \n",
       "2022-07-05  0.9591  0.9540  0.9575  0.9501  0.9446  0.9471      0.956929   \n",
       "\n",
       "            expanding_mean  time sentiment_score  \n",
       "date                                              \n",
       "2022-06-22             NaN     0        0.092788  \n",
       "2022-06-23        0.948050     1        0.092788  \n",
       "2022-06-24        0.947733     2        0.092788  \n",
       "2022-06-27        0.946950     3        0.092788  \n",
       "2022-06-28        0.947580     4        0.092788  \n",
       "2022-06-29        0.949233     5        0.092788  \n",
       "2022-06-30        0.949914     6        0.092788  \n",
       "2022-07-01        0.951063     7        0.092788  \n",
       "2022-07-04        0.951978     8        0.092788  \n",
       "2022-07-05        0.954170     9        0.092788  "
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_pairs.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "604d6883",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>from symbol</th>\n",
       "      <th>to symbol</th>\n",
       "      <th>open</th>\n",
       "      <th>high</th>\n",
       "      <th>low</th>\n",
       "      <th>close</th>\n",
       "      <th>lag_1</th>\n",
       "      <th>lag_2</th>\n",
       "      <th>lag_3</th>\n",
       "      <th>lag_4</th>\n",
       "      <th>lag_5</th>\n",
       "      <th>lag_6</th>\n",
       "      <th>lag_7</th>\n",
       "      <th>rolling_mean</th>\n",
       "      <th>expanding_mean</th>\n",
       "      <th>time</th>\n",
       "      <th>sentiment_score</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2022-10-26</th>\n",
       "      <td>NZD</td>\n",
       "      <td>SEK</td>\n",
       "      <td>6.2921</td>\n",
       "      <td>6.3517</td>\n",
       "      <td>6.2853</td>\n",
       "      <td>6.3005</td>\n",
       "      <td>6.2852</td>\n",
       "      <td>6.3241</td>\n",
       "      <td>6.3951</td>\n",
       "      <td>6.3897</td>\n",
       "      <td>6.3352</td>\n",
       "      <td>6.2840</td>\n",
       "      <td>6.2769</td>\n",
       "      <td>6.330543</td>\n",
       "      <td>6.411047</td>\n",
       "      <td>90</td>\n",
       "      <td>0.160037</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-10-27</th>\n",
       "      <td>NZD</td>\n",
       "      <td>SEK</td>\n",
       "      <td>6.3024</td>\n",
       "      <td>6.4091</td>\n",
       "      <td>6.2454</td>\n",
       "      <td>6.3798</td>\n",
       "      <td>6.3005</td>\n",
       "      <td>6.2852</td>\n",
       "      <td>6.3241</td>\n",
       "      <td>6.3951</td>\n",
       "      <td>6.3897</td>\n",
       "      <td>6.3352</td>\n",
       "      <td>6.2840</td>\n",
       "      <td>6.344229</td>\n",
       "      <td>6.410708</td>\n",
       "      <td>91</td>\n",
       "      <td>0.160037</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-10-28</th>\n",
       "      <td>NZD</td>\n",
       "      <td>SEK</td>\n",
       "      <td>6.3808</td>\n",
       "      <td>6.4186</td>\n",
       "      <td>6.3355</td>\n",
       "      <td>6.3431</td>\n",
       "      <td>6.3798</td>\n",
       "      <td>6.3005</td>\n",
       "      <td>6.2852</td>\n",
       "      <td>6.3241</td>\n",
       "      <td>6.3951</td>\n",
       "      <td>6.3897</td>\n",
       "      <td>6.3352</td>\n",
       "      <td>6.345357</td>\n",
       "      <td>6.409981</td>\n",
       "      <td>92</td>\n",
       "      <td>0.160037</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-10-31</th>\n",
       "      <td>NZD</td>\n",
       "      <td>SEK</td>\n",
       "      <td>6.3576</td>\n",
       "      <td>6.4277</td>\n",
       "      <td>6.3427</td>\n",
       "      <td>6.3853</td>\n",
       "      <td>6.3431</td>\n",
       "      <td>6.3798</td>\n",
       "      <td>6.3005</td>\n",
       "      <td>6.2852</td>\n",
       "      <td>6.3241</td>\n",
       "      <td>6.3951</td>\n",
       "      <td>6.3897</td>\n",
       "      <td>6.344729</td>\n",
       "      <td>6.409718</td>\n",
       "      <td>93</td>\n",
       "      <td>0.160037</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-11-01</th>\n",
       "      <td>NZD</td>\n",
       "      <td>SEK</td>\n",
       "      <td>6.3853</td>\n",
       "      <td>6.4542</td>\n",
       "      <td>6.3853</td>\n",
       "      <td>6.4308</td>\n",
       "      <td>6.3853</td>\n",
       "      <td>6.3431</td>\n",
       "      <td>6.3798</td>\n",
       "      <td>6.3005</td>\n",
       "      <td>6.2852</td>\n",
       "      <td>6.3241</td>\n",
       "      <td>6.3951</td>\n",
       "      <td>6.349829</td>\n",
       "      <td>6.409940</td>\n",
       "      <td>94</td>\n",
       "      <td>0.160037</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-11-02</th>\n",
       "      <td>NZD</td>\n",
       "      <td>SEK</td>\n",
       "      <td>6.4285</td>\n",
       "      <td>6.4854</td>\n",
       "      <td>6.4167</td>\n",
       "      <td>6.4521</td>\n",
       "      <td>6.4308</td>\n",
       "      <td>6.3853</td>\n",
       "      <td>6.3431</td>\n",
       "      <td>6.3798</td>\n",
       "      <td>6.3005</td>\n",
       "      <td>6.2852</td>\n",
       "      <td>6.3241</td>\n",
       "      <td>6.368114</td>\n",
       "      <td>6.410379</td>\n",
       "      <td>95</td>\n",
       "      <td>0.160037</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-11-03</th>\n",
       "      <td>NZD</td>\n",
       "      <td>SEK</td>\n",
       "      <td>6.4567</td>\n",
       "      <td>6.4721</td>\n",
       "      <td>6.3954</td>\n",
       "      <td>6.4480</td>\n",
       "      <td>6.4521</td>\n",
       "      <td>6.4308</td>\n",
       "      <td>6.3853</td>\n",
       "      <td>6.3431</td>\n",
       "      <td>6.3798</td>\n",
       "      <td>6.3005</td>\n",
       "      <td>6.2852</td>\n",
       "      <td>6.391371</td>\n",
       "      <td>6.410767</td>\n",
       "      <td>96</td>\n",
       "      <td>0.160037</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-11-04</th>\n",
       "      <td>NZD</td>\n",
       "      <td>SEK</td>\n",
       "      <td>6.4347</td>\n",
       "      <td>6.4877</td>\n",
       "      <td>6.4347</td>\n",
       "      <td>6.4581</td>\n",
       "      <td>6.4480</td>\n",
       "      <td>6.4521</td>\n",
       "      <td>6.4308</td>\n",
       "      <td>6.3853</td>\n",
       "      <td>6.3431</td>\n",
       "      <td>6.3798</td>\n",
       "      <td>6.3005</td>\n",
       "      <td>6.413886</td>\n",
       "      <td>6.411250</td>\n",
       "      <td>97</td>\n",
       "      <td>0.160037</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-11-07</th>\n",
       "      <td>NZD</td>\n",
       "      <td>SEK</td>\n",
       "      <td>6.4066</td>\n",
       "      <td>6.4443</td>\n",
       "      <td>6.3813</td>\n",
       "      <td>6.4368</td>\n",
       "      <td>6.4581</td>\n",
       "      <td>6.4480</td>\n",
       "      <td>6.4521</td>\n",
       "      <td>6.4308</td>\n",
       "      <td>6.3853</td>\n",
       "      <td>6.3431</td>\n",
       "      <td>6.3798</td>\n",
       "      <td>6.422029</td>\n",
       "      <td>6.411508</td>\n",
       "      <td>98</td>\n",
       "      <td>0.160037</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-11-08</th>\n",
       "      <td>NZD</td>\n",
       "      <td>SEK</td>\n",
       "      <td>6.4380</td>\n",
       "      <td>6.4468</td>\n",
       "      <td>6.3551</td>\n",
       "      <td>6.4039</td>\n",
       "      <td>6.4368</td>\n",
       "      <td>6.4581</td>\n",
       "      <td>6.4480</td>\n",
       "      <td>6.4521</td>\n",
       "      <td>6.4308</td>\n",
       "      <td>6.3853</td>\n",
       "      <td>6.3431</td>\n",
       "      <td>6.430714</td>\n",
       "      <td>6.411432</td>\n",
       "      <td>99</td>\n",
       "      <td>0.160037</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           from symbol to symbol    open    high     low   close   lag_1  \\\n",
       "date                                                                       \n",
       "2022-10-26         NZD       SEK  6.2921  6.3517  6.2853  6.3005  6.2852   \n",
       "2022-10-27         NZD       SEK  6.3024  6.4091  6.2454  6.3798  6.3005   \n",
       "2022-10-28         NZD       SEK  6.3808  6.4186  6.3355  6.3431  6.3798   \n",
       "2022-10-31         NZD       SEK  6.3576  6.4277  6.3427  6.3853  6.3431   \n",
       "2022-11-01         NZD       SEK  6.3853  6.4542  6.3853  6.4308  6.3853   \n",
       "2022-11-02         NZD       SEK  6.4285  6.4854  6.4167  6.4521  6.4308   \n",
       "2022-11-03         NZD       SEK  6.4567  6.4721  6.3954  6.4480  6.4521   \n",
       "2022-11-04         NZD       SEK  6.4347  6.4877  6.4347  6.4581  6.4480   \n",
       "2022-11-07         NZD       SEK  6.4066  6.4443  6.3813  6.4368  6.4581   \n",
       "2022-11-08         NZD       SEK  6.4380  6.4468  6.3551  6.4039  6.4368   \n",
       "\n",
       "             lag_2   lag_3   lag_4   lag_5   lag_6   lag_7  rolling_mean  \\\n",
       "date                                                                       \n",
       "2022-10-26  6.3241  6.3951  6.3897  6.3352  6.2840  6.2769      6.330543   \n",
       "2022-10-27  6.2852  6.3241  6.3951  6.3897  6.3352  6.2840      6.344229   \n",
       "2022-10-28  6.3005  6.2852  6.3241  6.3951  6.3897  6.3352      6.345357   \n",
       "2022-10-31  6.3798  6.3005  6.2852  6.3241  6.3951  6.3897      6.344729   \n",
       "2022-11-01  6.3431  6.3798  6.3005  6.2852  6.3241  6.3951      6.349829   \n",
       "2022-11-02  6.3853  6.3431  6.3798  6.3005  6.2852  6.3241      6.368114   \n",
       "2022-11-03  6.4308  6.3853  6.3431  6.3798  6.3005  6.2852      6.391371   \n",
       "2022-11-04  6.4521  6.4308  6.3853  6.3431  6.3798  6.3005      6.413886   \n",
       "2022-11-07  6.4480  6.4521  6.4308  6.3853  6.3431  6.3798      6.422029   \n",
       "2022-11-08  6.4581  6.4480  6.4521  6.4308  6.3853  6.3431      6.430714   \n",
       "\n",
       "            expanding_mean  time sentiment_score  \n",
       "date                                              \n",
       "2022-10-26        6.411047    90        0.160037  \n",
       "2022-10-27        6.410708    91        0.160037  \n",
       "2022-10-28        6.409981    92        0.160037  \n",
       "2022-10-31        6.409718    93        0.160037  \n",
       "2022-11-01        6.409940    94        0.160037  \n",
       "2022-11-02        6.410379    95        0.160037  \n",
       "2022-11-03        6.410767    96        0.160037  \n",
       "2022-11-04        6.411250    97        0.160037  \n",
       "2022-11-07        6.411508    98        0.160037  \n",
       "2022-11-08        6.411432    99        0.160037  "
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_pairs.tail(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36d23de9",
   "metadata": {},
   "source": [
    "Save all_pairs to pickle:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "8c95ff6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_pairs.to_pickle('all_pairs.pkl')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
